
x_input = read.csv("x.csv", header = F)
y_output = read.csv("y.csv", header = F)
time = read.csv("time.csv", header = F)
#fixing time
time = read.csv("time.csv", header = F, skip = 1)
time = rbind(0, time)

#time series plot
M = data.matrix(input_output_data.1)
dim(M)

X = rbind( matrix(input_output_data.1$'x1',1,201) , matrix(input_output_data.1$'x2',1,201) , matrix(input_output_data.1$'x3',1,201) , 
           matrix(input_output_data.1$'x4',1,201) , matrix(input_output_data.1$'y',1,201) )



#Time Series Plot
par(mar =c(4, 4, 4, 2) + 0.1)
plot(M[,1],M[,2], xlab="Time(sec)",ylab="input x1",type = "l",col="darkorange2")
plot(M[,1],M[,3], xlab="Time(sec)",ylab="input x2",type = "l",col="deepskyblue1")
plot(M[,1],M[,4], xlab="Time(sec)",ylab="input x3",type = "l",col="chartreuse3")
plot(M[,1],M[,5], xlab="Time(sec)",ylab="input x4",type = "l",col="red3")
plot(M[,1],M[,6], xlab="Time(sec)",ylab="output y",type = "l",col="coral3")

#Visualizing the Distributions

library(fitdistrplus)

par(mar = rep(2, 4))

normal_dist_1=fitdist(M[,2], "norm")
plot(normal_dist_1)

normal_dist_2=fitdist(M[,3], "norm")
plot(normal_dist_2)

normal_dist_3=fitdist(M[,4], "norm")
plot(normal_dist_3)

normal_dist_4=fitdist(M[,5], "norm")
plot(normal_dist_4)

normal_dist_5=fitdist(M[,6], "norm")
plot(normal_dist_5)

heatmap(M)

#Checking the correlations
C12 = c(cor(M[,2],M[,3]))

C13 = c(cor(M[,2],M[,4]))

C14=c(cor(M[,2],M[,5]))

C15= c(cor(M[,2],M[,6]))

C23 =c(cor(M[,3],M[,4]))

C24 =c(cor(M[,3],M[,5]))

C25= c(cor(M[,3],M[,6]))

C34 =c(cor(M[,4],M[,5]))

C35 =c(cor(M[,4],M[,6]))

C45= c(cor(M[,5],M[,6]))

correlations = data.frame(C12,C13,C14,C15,C23,C24,C25,C34,C35,C45)
correlations

#Plotting Scatter Plot

par(mar =c(4, 4, 4, 2) + 0.1)

plot(M[,2],M[,3], xlab="input x1",ylab="input x2",col="darkolivegreen")

plot(M[,2],M[,4], xlab="input x1",ylab="input x3",col="magenta3")

plot(M[,2],M[,5], xlab="input x1",ylab="input x4",col="mediumturquoise")

plot(M[,2],M[,6], xlab="input x1",ylab="input x5",col="green")

plot(M[,3],M[,4], xlab="input x2",ylab="input x3",col="chartreuse3")

plot(M[,3],M[,5], xlab="input x2",ylab="input x4",col="darkorange2")

plot(M[,3],M[,6], xlab="input x2",ylab="input x5",col="slateblue1")

plot(M[,4],M[,5], xlab="input x3",ylab="input x4",col="brown")

plot(M[,4],M[,6], xlab="input x3",ylab="input x5",col="orchid3")

plot(M[,5],M[,6], xlab="input x4",ylab="input y",col="aquamarine4")

dim(M)

#Task(2) 2.1
M2 = M[,2:6]
ones = matrix(1, length(M2[,5]), 1)

#Model 1
x1 = M[,2]
x2 = M[,3]
x3 = M[,4]
x4 = M[,5]
y = M[,6]

x12 = matrix(x1^2)
x13 = matrix(x1^3)
x34 = matrix(x3^4)
X1 = cbind(x4,x1^2,x1^3,x3^4,ones)

thetaHat_1 = solve(t(X1) %*% X1) %*% t(X1) %*% y
print(thetaHat_1)

y_Hat_1 = X1 %*% thetaHat_1

error1 = y - y_Hat_1
RSS = norm(error1, type = "2")^2
RSS1 = sum((y-y_Hat_1)^2)
print(RSS)

#Model 2
x33 = matrix(x3^3)
x34 = matrix(x3^4)
X2 = cbind(x3^3,x3^4,ones)

thetaHat_2 = solve(t(X2) %*% X2) %*% t(X2) %*% y
print(thetaHat_2)

y_Hat_2 = X2 %*% thetaHat_2

error2 = y - y_Hat_2

RSS = norm(error2, type = "2")^2
RSS2 = sum((y-y_Hat_2)^2)
print(RSS)

#Model 3
x13 = matrix(x1^3)
x34 = matrix(x3^4)
X3 = cbind(x2,x1^3,x3^4,ones)
thetaHat_3 = solve(t(X3) %*% X3) %*% t(X3) %*% y
print(thetaHat_3)

y_Hat_3 = X3 %*% thetaHat_3

error3 = y - y_Hat_3

RSS = norm(error3, type = "2")^2
RSS3 = sum((y-y_Hat_3)^2)
print(RSS)

#Model 4
x13 = matrix(x1^3)
x34 = matrix(x3^4)
X4 = cbind(x4,x1^3,x3^4,ones)
thetaHat_4 = solve(t(X4) %*% X4) %*% t(X4) %*% y
print(thetaHat_4)

y_Hat_4 = X4 %*% thetaHat_4

error4 = y - y_Hat_4

RSS = norm(error4, type = "2")^2
RSS4 = sum((y-y_Hat_4)^2)
print(RSS)

#Model 5
x12 = matrix(x1^2)
x13 = matrix(x1^3)
x34 = matrix(x3^4)
x14 = matrix(x1^4)
X5 = cbind(x4,x1^2,x1^3,x3^4,x1^4,ones)
thetaHat_5 = solve(t(X5) %*% X5) %*% t(X5) %*% y
print(thetaHat_5)

y_Hat_5 = X5 %*% thetaHat_5

error5 = y - y_Hat_5

RSS = norm(error5, type = "2")^2
RSS5 = sum((y-y_Hat_5)^2)
print(RSS)

#Task 2.3
n = 201

P1 = -(n/2)*log(2*pi)-(n/2)*(log(RSS1)/(n-1))-((n-1)/2)
print(P1)

P2 = -(n/2)*log(2*pi)-(n/2)*(log(RSS2)/(n-1))-((n-1)/2)
print(P2)                                 

P3 = -(n/2)*log(2*pi)-(n/2)*(log(RSS3)/(n-1))-((n-1)/2)
print(P3)

P4 = -(n/2)*log(2*pi)-(n/2)*(log(RSS4)/(n-1))-((n-1)/2)
print(P4)

P5 = -(n/2)*log(2*pi)-(n/2)*(log(RSS5)/(n-1))-((n-1)/2)
print(P5)

#Task 2.4 (AIC)
k1 = 5
AIC1 = 2*(k1)-(2)*(P1)
print(AIC1)

k2 = 3
AIC2 = 2*(k2)-(2)*(P2)
print(AIC2)

k3 = 4
AIC3 = 2*(k3)-(2)*(P3)
print(AIC3)

k4 = 4
AIC4 = 2*(k4)-(2)*(P4)
print(AIC4)

k5 = 6
AIC5 = 2*(k5)-(2)*(P5)
print(AIC5)

#(BIC)
BIC1 = k1*(log(n))-(2)*(P1)
print(BIC1)

BIC2 = k2*(log(n))-(2)*(P2)
print(BIC2)

BIC3 = k3*(log(n))-(2)*(P3)
print(BIC3)

BIC4 = k4*(log(n))-(2)*(P4)
print(BIC4)

BIC5 = k5*(log(n))-(2)*(P5)
print(BIC5)

#Task 2.5
E1 = error1
qqnorm(E1)
qqline(E1,col='red')

E2 = error2
qqnorm(E2)
qqline(E2,col='red')

E3 = error3
qqnorm(E3)
qqline(E3,col='red')

E4 = error4
qqnorm(E4)
qqline(E4,col='red')

E5 = error5
qqnorm(E5)
qqline(E5,col='red')

#Task 2.7
#install.packages('caTools')
#library(caTools)
val_X = X5
train_index = sample(1:nrow(val_X), 0.7 * nrow(val_X))
test_index = setdiff(0:nrow(val_X), train)
# Build X_train, y_train, X_test, y_test
X_train = val_X[train_index,]
y_train = val_X[train_index,]
X_test = val_X[test_index,]
y_test = val_X[test_index,]

model_parameter_5 = solve(t(X_train) %*% X_train) %*% t(X_train) %*% y_train
print(model_parameter_5)
#(2)
y_hat_model_pred = X_test %*% theta_Hat_val
print(y_hat_model_pred)
#(3)
df <- subset(val_X,select=-c(ones))
print(df)

x= val_X

y= y_hat_model_pred

lm.out = lm(y ~ x)
newx = seq(min(x),max(x),by = 0.05)

conf_interval = predict(lm.out, newdata=data.frame(x=newx), interval="confidence",level = 0.95)
plot(x, y, xlab="x", ylab="y", main="Regression")
abline(lm.out, col="lightblue")
lines(newx, conf_interval[,2], col="blue", lty=2)
lines(newx, conf_interval[,3], col="blue", lty=2)


######sub
library(caTools)
final_subset_model_val = matrix(M[,6])
val_X = cbind(x4,x1^2,x1^3,x3^4,x1^4,ones) #########your column details and don't include ones

smp_size <- floor(0.7 * nrow(val_X))
set.seed(123)
train_ind <- sample(seq_len(nrow(val_X)), size = smp_size)
X_train <- val_X[train_ind, ]
X_test <- val_X[-train_ind, ]

sample = sample.split(final_subset_model_val,SplitRatio = 0.7) 
y_train =subset(final_subset_model_val,sample ==TRUE) 
y_test=subset(final_subset_model_val, sample==FALSE)

theta_Hat_val = solve(t(X_train) %*% X_train) %*% t(X_train) %*% y_train

y_hat_val_5 = X_test %*% theta_Hat_val
print(y_hat_val_5)
dim(y_hat_val_5)
#######
sigma_2 = c()
X_cov5 = c()
#cov_thetaHat = 1 * (solve(t(X5) %*% X5))
sigma_2 = RSS5/200 # error variance sigma^2

X_cov5 = cbind(x4,x1^2,x1^3,x3^4,x1^4,ones)

cov_thetaHat = 1 * (solve(t(X_cov5) %*% X_cov5))
dim(cov_thetaHat)
dim(X_cov5)
var_y_hat = matrix(0 , 201 , 1)

for( i in 1:201){
  Xi = matrix( X_cov5[i,] , 1 , 6 ) # X[i,] creates a vector. Convert it to matrix
  var_y_hat[i,1] = Xi %*% cov_thetaHat %*% t(Xi) # same as sigma_2 * ( X_i %% ( solve(t(X) %% X)  ) %*% t(X_i) )
  print(var_y_hat[i,1])
}

set.seed(123)
smp_size <- floor(0.8 * nrow(X_cov5))
train_ind <- sample(seq_len(nrow(X_cov5)), size = smp_size)
x_model_trainCI <- X_cov5[train_ind, ]
x_model_testCI <- X_cov5[-train_ind, ]

range(x_model_trainCI[,1],x_model_trainCI[,2],x_model_trainCI[,3],x_model_trainCI[,3],x_model_trainCI[,4],x_model_trainCI[,5],x_model_trainCI[,6])
x_CI = seq(-460.2943,3553.9726, by=20.02)
x_CI

CI = 2 * sqrt(var_y_hat) # Confidence interval
print(CI)

x_input = M[,2:5]
y_input = M[,6]  
thetaHat = solve(t(X_cov5) %*% X_cov5) %*% t(X_cov5) %*% y_input

y_hat = X_cov5 %*% thetaHat

plot(x_CI, y_hat , type = "l")
segments(x_CI, y_hat-CI, x_CI, y_hat+CI,col ="green")

#Task 3
abs_val1= matrix((x4), nrow=3)
abs_val1
max(abs(abs_val1))

abs_val2= matrix((x12), nrow=3)
abs_val2
max(abs(abs_val2))

abs_val3= matrix((x13), nrow=3)
abs_val3
max(abs(abs_val3))

abs_val4= matrix((x34), nrow=3)
abs_val4
max(abs(abs_val4))

abs_val5= matrix((x14), nrow=3)
abs_val5
max(abs(abs_val5))



final_model_main = X5

X_model = X_cov5

ABC_theta = cbind("abs_val4","abs_val5")

dim(ABC_theta)
dim(X_model)
length(ABC_theta)

ABC_reject = c()
ABC_accept = c()
for (i in 1:3000){
  ABC_y_Hat= X_model %*% ABC_theta[i,]
  ABC_error = final_model_main - ABC_y_Hat
  SSE = norm(ABC_error, type = "2")^2
  SSE1 = sum((final_model_main-ABC_y_Hat)^2)
  ABC_MSE = SSE/201
  if (ABC_MSE > 5 ){
    reject = ABC_theta[i,]
    ABC_reject = rbind(ABC_reject,reject)
  }
  else if (ABC_MSE < 5 ) {
    accept = ABC_theta[i,]
    ABC_accept  = rbind(ABC_accept,accept)
  }
  
}

dim(ABC_reject)
dim(ABC_accept)

ABC_accept

sum(ABC_accept)

probility= c()
for (i in 1:473){
  for (j in 1:6){
    prob = ABC_accept[i,j]
    probility = rbind(probility,prob)
  }
}

probility

probility_joint = matrix(probility,nrow=473, ncol =6)

plot(probility_joint[,1],probility_joint[,2], pch = 15, col = c("black", "red"), xlab = "theta_1", ylab = "theta_2")
legend(0.42,0.52,legend = c("theta_1", "theta_2"), col= c("black","red"), lty=1:2, cex=0.8)

hist(probility_joint[,1], col = "coral3",border = "black")

hist(probility_joint[,2], col = "darkgoldenrod4",border = "black")
